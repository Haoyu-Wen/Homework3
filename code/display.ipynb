{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***usage***\n",
    "- 查看eval的结果\n",
    "- 根据输入的图片（路径），产生输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "# from modi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayEvalResult(dataset, id, ref_path, hyp_path):\n",
    "    \"\"\"\n",
    "    :brief: read eval results by ref_path,hyp_path\n",
    "    :param dataset: dataset name\n",
    "    :param id :image index\n",
    "    :param ref_path: reference path\n",
    "    :param hyp_path: answer path\n",
    "    \"\"\"\n",
    "    # with open(os.join(dataset,'TEST',\"0\",str(id)), )\n",
    "    img1 = Image.open(os.path.join('dataset', dataset,'TEST',\"imgs\", \"0\",str(id)+\".png\"))\n",
    "    img2 = Image.open(os.path.join('dataset', dataset,'TEST',\"imgs\",\"1\",str(id)+\".png\"))\n",
    "    img3 = Image.open(os.path.join('dataset', dataset,'TEST',\"imgs\",\"2\",str(id)+\".png\"))\n",
    "    with open(ref_path, 'r', encoding='utf-8') as f:\n",
    "        ref = json.load(f)\n",
    "    with open(hyp_path, 'r', encoding='utf-8') as f:\n",
    "        hyp = json.load(f)\n",
    "    img1.show(f\"{id}: before\")\n",
    "    img2.show(f\"{id}: during\")\n",
    "    img3.show(f\"{id}: after\")\n",
    "    print(f\"reference:\")\n",
    "    for i in \"\".join(ref[str(id)]).split(\"<sep>\"):\n",
    "        print(i)\n",
    "    print(\"###########\")   \n",
    "    print(f\"answers:\")\n",
    "    for i in \"\".join(hyp[str(id)]).split(\"<sep>\"):\n",
    "        print(i)\n",
    "    print(\"&&&&&&&&&&&\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract feature\n",
    "transform_to_tensor = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "# resnet50 = models.resnet50(pretrained=True)\n",
    "# resnet50.eval()\n",
    "\n",
    "def read_img(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    img = img.convert('RGB')# read png...\n",
    "    img = transform_to_tensor(img).to(device)\n",
    "    img = img.unsqueeze(0)\n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_decoder(decoder, memory, word_map, rev_word_map, beam_size, max_len=120):\n",
    "    k = beam_size\n",
    "    vocab_size = len(word_map)\n",
    "    \n",
    "    start_token = word_map['<start>']\n",
    "    end_token = word_map['<end>']\n",
    "    \n",
    "    # Initialize sequences with the start token\n",
    "    sequences = [[start_token]]\n",
    "    scores = torch.zeros(k, 1).to(device)\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        all_candidates = []\n",
    "        \n",
    "        for i in range(len(sequences)):\n",
    "            seq = sequences[i]\n",
    "            score = scores[i]\n",
    "            \n",
    "            if seq[-1] == end_token:\n",
    "                all_candidates.append((seq, score))\n",
    "                continue\n",
    "            \n",
    "            tgt = torch.tensor(seq).unsqueeze(1).to(device)\n",
    "            tgt_length = tgt.size(0)\n",
    "            \n",
    "            mask = (torch.triu(torch.ones(tgt_length, tgt_length)) == 1).transpose(0, 1)\n",
    "            mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "            mask = mask.to(device)\n",
    "            \n",
    "            tgt_embedding = decoder.vocab_embedding(tgt)\n",
    "            tgt_embedding = decoder.position_encoding(tgt_embedding)\n",
    "            pred = decoder.transformer(tgt_embedding, memory, tgt_mask=mask)\n",
    "            pred = decoder.wdc(pred)\n",
    "            pred = pred[-1, 0, :]\n",
    "            \n",
    "            topk_probs, topk_indices = torch.topk(pred, k, dim=-1)\n",
    "            \n",
    "            for j in range(k):\n",
    "                candidate = [seq + [topk_indices[j].item()], score - torch.log(topk_probs[j])]\n",
    "                all_candidates.append(candidate)\n",
    "        \n",
    "        ordered = sorted(all_candidates, key=lambda x: x[1])\n",
    "        sequences, scores = zip(*ordered[:k])\n",
    "    \n",
    "    best_sequence = sequences[0]\n",
    "    return best_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(dict_, value):\n",
    "  return [k for k, v in dict_.items() if v == value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wordmap(word_map_path):\n",
    "    with open(word_map_path, 'r') as f:\n",
    "        word_map = json.load(f)\n",
    "    return word_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(img1, img2, img3, ckeckpoint, word_map_path, beam_size, decode_twice=False):\n",
    "    checkpoint = torch.load(ckeckpoint, map_location='cuda:0')\n",
    "    encoder = checkpoint['encoder']\n",
    "    encoder = encoder.to(device)\n",
    "    encoder.eval()\n",
    "\n",
    "    decoder = checkpoint['decoder']\n",
    "    decoder = decoder.to(device)\n",
    "    decoder.eval()\n",
    "\n",
    "    wordmap = load_wordmap(word_map_path=word_map_path)\n",
    "    rev_word_map = {v: k for k, v in wordmap.items()}\n",
    "\n",
    "    img1 = read_img(img_path=img1)\n",
    "    img2 = read_img(img_path=img2)\n",
    "    img3 = read_img(img_path=img3)\n",
    "    memory = encoder(img1, img2, img3)\n",
    "    if decode_twice:\n",
    "        assert type(memory)==tuple\n",
    "        memory1, memory2 = memory\n",
    "        seq1 = beam_search_decoder(decoder=decoder, memory=memory1, word_map=wordmap, rev_word_map=rev_word_map, beam_size=beam_size, max_len=120)\n",
    "        seq2 = beam_search_decoder(decoder=decoder, memory=memory2, word_map=wordmap, rev_word_map=rev_word_map, beam_size=beam_size, max_len=120)\n",
    "        hyp = [w for w in seq1 if w not in {wordmap['<start>'], wordmap['<end>'], wordmap['<pad>']}]\n",
    "        hyp.extend([w for w in seq2 if w not in {wordmap['<start>'], wordmap['<end>'], wordmap['<pad>']}])\n",
    "        \n",
    "    else:\n",
    "        if type(memory)==tuple:\n",
    "            memory1, memory2 = memory\n",
    "            memory = (memory1+memory2)/2\n",
    "        seq = beam_search_decoder(decoder=decoder, memory=memory, word_map=wordmap, rev_word_map=rev_word_map, beam_size=beam_size, max_len=120)\n",
    "        hyp = [w for w in seq if w not in {wordmap['<start>'], wordmap['<end>'], wordmap['<pad>']}]\n",
    "    \n",
    "    line_hypo=\"\"\n",
    "    for word_idx in hyp:\n",
    "        word = get_key(wordmap, word_idx)\n",
    "        line_hypo += word[0] + \" \"\n",
    "\n",
    "    print(\"#######\")\n",
    "    print(\"Answer:\")\n",
    "    hyp = \"\".join(line_hypo.split(\"<sep>\"))\n",
    "    print(hyp)\n",
    "    return hyp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdvanceMCCFormers-S 例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference:\n",
      "There is no longer a small gray rubber sphere . \n",
      " The large red rubber cube has disappeared . \n",
      " A new large green metal cylinder is visible . \n",
      " The large cyan metal sphere has been moved . \n",
      " The small blue metal sphere is in a different location . \n",
      " Someone removed the large brown rubber cube . \n",
      "###########\n",
      "answer:\n",
      "The large purple rubber sphere is missing . \n",
      " The large purple rubber sphere is missing . \n",
      " The small purple rubber cylinder is missing . A new large purple metal sphere is visible . \n",
      " The large purple metal sphere was moved from its original location . \n",
      " The large purple metal sphere was moved from its original original location . \n",
      " A new large purple metal cylinder is visible . there . A different location . \n",
      " A large purple metal cylinder . \n",
      "&&&&&&&&&&&\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: no \"view\" rule for type \"image/png\" passed its test case\n",
      "       (for more information, add \"--debug=1\" on the command line)\n",
      "Error: no \"view\" rule for type \"image/png\" passed its test case\n",
      "       (for more information, add \"--debug=1\" on the command line)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: no \"view\" rule for type \"image/png\" passed its test case\n",
      "       (for more information, add \"--debug=1\" on the command line)\n"
     ]
    }
   ],
   "source": [
    "dataset = \"CLEVR\"\n",
    "id = 0\n",
    "eval_root = \"./eval_results/CLEVR/AdvanceMCCFormers-S\"\n",
    "ref_path, hyp_path = eval_root+\"/advance_CLEVRhat_decode_twice_epoch9decode_twice_gts.json\", eval_root+\"/advance_CLEVRhat_decode_twice_epoch9decode_twice_res.json\"\n",
    "displayEvalResult(dataset=dataset, id=id, ref_path=ref_path, hyp_path=hyp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdvanceMCCFormers-D例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######\n",
      "Answer:\n",
      "The small green rubber sphere is missing .  The large green rubber sphere is missing .  The small green rubber sphere is missing . The large green rubber sphere is missing .  The large green metal sphere is missing .  The large green metal sphere is missing . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The small green rubber sphere is missing .  The large green rubber sphere is missing .  The small green rubber sphere is missing . The large green rubber sphere is missing .  The large green metal sphere is missing .  The large green metal sphere is missing . '"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = \"./dataset/CLEVR/TEST/imgs/0/0.png\"\n",
    "img2 = \"./dataset/CLEVR/TEST/imgs/1/0.png\"\n",
    "img3 = \"./dataset/CLEVR/TEST/imgs/2/0.png\"\n",
    "# Image.open(img1).show(\"before\")\n",
    "# Image.open(img2).show(\"during\")\n",
    "# Image.open(img3).show(\"after\")\n",
    "\n",
    "checkpoint = \"./result/AdvanceMCCFormers-D/CLEVRhat/checkpoint_epoch_9first_advance_CLEVRhat_use_2_imgs.pth.tar\" #使用的是采用高阶训练的模型\n",
    "word_map_path=\"./dataset/CLEVRhat/wordmap/wordmap.json\"\n",
    "beam_size = 3\n",
    "answer(img1=img1, img2=img2, img3=img3, ckeckpoint=checkpoint, word_map_path=word_map_path, beam_size=beam_size, decode_twice=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "format",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
